{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyspark\n",
    "# !pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import sklearn.model_selection as model_selection\n",
    "import pyspark\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import KFold, cross_val_score,StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>H_Cal_Consump</th>\n",
       "      <th>Veg_Consump</th>\n",
       "      <th>Water_Consump</th>\n",
       "      <th>Alcohol_Consump</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Meal_Count</th>\n",
       "      <th>Food_Between_Meals</th>\n",
       "      <th>Fam_Hist</th>\n",
       "      <th>H_Cal_Burn</th>\n",
       "      <th>Phys_Act</th>\n",
       "      <th>Time_E_Dev</th>\n",
       "      <th>Transport</th>\n",
       "      <th>Body_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>22.547298</td>\n",
       "      <td>1.722461</td>\n",
       "      <td>51.881263</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.663421</td>\n",
       "      <td>1.041110</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0.794402</td>\n",
       "      <td>1.391948</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Body Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>19.799054</td>\n",
       "      <td>1.743702</td>\n",
       "      <td>54.927529</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.847264</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.289260</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.680844</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Body Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>17.823438</td>\n",
       "      <td>1.708406</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.642241</td>\n",
       "      <td>1.099231</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.452590</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0.418875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Body Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>19.007177</td>\n",
       "      <td>1.690727</td>\n",
       "      <td>49.895716</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.212908</td>\n",
       "      <td>1.029703</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.207071</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Body Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>19.729250</td>\n",
       "      <td>1.793315</td>\n",
       "      <td>58.195150</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.508835</td>\n",
       "      <td>2.076933</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.435905</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.026668</td>\n",
       "      <td>1.443328</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Body Level 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender        Age    Height     Weight H_Cal_Consump  Veg_Consump   \n",
       "0  Female  22.547298  1.722461  51.881263           yes     2.663421  \\\n",
       "1    Male  19.799054  1.743702  54.927529           yes     2.000000   \n",
       "2  Female  17.823438  1.708406  50.000000           yes     1.642241   \n",
       "3  Female  19.007177  1.690727  49.895716           yes     1.212908   \n",
       "4    Male  19.729250  1.793315  58.195150           yes     2.508835   \n",
       "\n",
       "   Water_Consump Alcohol_Consump Smoking  Meal_Count Food_Between_Meals   \n",
       "0       1.041110              no      no    3.000000         Frequently  \\\n",
       "1       2.847264       Sometimes      no    3.289260          Sometimes   \n",
       "2       1.099231       Sometimes      no    3.452590          Sometimes   \n",
       "3       1.029703       Sometimes      no    3.207071          Sometimes   \n",
       "4       2.076933              no      no    3.435905          Sometimes   \n",
       "\n",
       "  Fam_Hist H_Cal_Burn  Phys_Act  Time_E_Dev              Transport   \n",
       "0      yes         no  0.794402    1.391948  Public_Transportation  \\\n",
       "1      yes         no  1.680844    2.000000  Public_Transportation   \n",
       "2       no         no  0.418875    1.000000  Public_Transportation   \n",
       "3       no         no  2.000000    1.000000  Public_Transportation   \n",
       "4      yes         no  2.026668    1.443328             Automobile   \n",
       "\n",
       "     Body_Level  \n",
       "0  Body Level 1  \n",
       "1  Body Level 1  \n",
       "2  Body Level 1  \n",
       "3  Body Level 1  \n",
       "4  Body Level 1  "
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('body_level_classification_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Categorical to Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"Gender\", \"H_Cal_Consump\", \"Alcohol_Consump\", \"Smoking\", \"Food_Between_Meals\", \"Fam_Hist\", \"H_Cal_Burn\", \"Transport\",\"Body_Level\"]:\n",
    "    df[col] = pd.Categorical(df[col], categories=df[col].unique()).codes\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi_class Parameter:\n",
    "The handling of multinomial classification problems. This can be 'auto', 'ovr', or 'multinomial'. The default value is 'auto'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression Classifier with multinomial\n",
      "Training Accurracy: 89.44820909970959%\n",
      "Testing Accurracy: 86.93693693693693%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87        57\n",
      "           1       0.83      0.56      0.67        61\n",
      "           2       0.78      0.91      0.84       122\n",
      "           3       0.96      0.92      0.94       204\n",
      "\n",
      "    accuracy                           0.87       444\n",
      "   macro avg       0.85      0.83      0.83       444\n",
      "weighted avg       0.88      0.87      0.87       444\n",
      "\n",
      "Mean F1 score: 0.8283040110496392\n",
      "Accuracy after applying cross validation: 0.82830 (+/- 0.02952)\n",
      "------------------------------------------------------------------------\n",
      "Training Logistic Regression Classifier with ovr\n",
      "Training Accurracy: 84.99515972894483%\n",
      "Testing Accurracy: 81.08108108108108%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85        57\n",
      "           1       0.63      0.28      0.39        61\n",
      "           2       0.70      0.80      0.75       122\n",
      "           3       0.92      0.94      0.93       204\n",
      "\n",
      "    accuracy                           0.81       444\n",
      "   macro avg       0.76      0.74      0.73       444\n",
      "weighted avg       0.80      0.81      0.79       444\n",
      "\n",
      "Mean F1 score: 0.7452821650934279\n",
      "Accuracy after applying cross validation: 0.74528 (+/- 0.02024)\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# separate the features and target variable\n",
    "X = df.drop('Body_Level', axis=1)\n",
    "y = df['Body_Level']\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size=0.3, random_state=42) \n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "for multi_class in ('multinomial', 'ovr'):\n",
    "    print(f\"Training Logistic Regression Classifier with {multi_class}\")\n",
    "    model = LogisticRegression(multi_class = multi_class,max_iter = 30000).fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_train_predict = model.predict(X_train)\n",
    "    print(f\"Training Accurracy: {accuracy_score(y_train, y_train_predict) * 100}%\")\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    print(f\"Testing Accurracy: {accuracy_score(y_test, y_test_predict) * 100}%\")\n",
    "\n",
    "\n",
    "    # create a KFold object\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    # perform cross-validation\n",
    "    scores = cross_val_score(model, X, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "    # Print the classification report and mean F1 score\n",
    "    print(classification_report(y_test, model.predict(X_test)))\n",
    "    print(\"Mean F1 score:\", scores.mean())\n",
    "\n",
    "    # print the mean and standard deviation of the scores\n",
    "    print(f\"Accuracy after applying cross validation: {scores.mean():.5f} (+/- {scores.std():.5f})\")\n",
    "    print(\"------------------------------------------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solver Parameter: \n",
    "The algorithm to be used for optimization. This can be 'newton-cg', 'lbfgs', 'liblinear', 'sag', or 'saga'. The default value is 'lbfgs'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression Classifier with newton-cg solver\n",
      "Training Accurracy: 89.351403678606%\n",
      "Testing Accurracy: 86.93693693693693%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87        57\n",
      "           1       0.83      0.56      0.67        61\n",
      "           2       0.78      0.91      0.84       122\n",
      "           3       0.96      0.92      0.94       204\n",
      "\n",
      "    accuracy                           0.87       444\n",
      "   macro avg       0.85      0.83      0.83       444\n",
      "weighted avg       0.88      0.87      0.87       444\n",
      "\n",
      "Mean F1 score: 0.8283040110496392\n",
      "Accuracy after applying cross validation: 0.82830 (+/- 0.02952)\n",
      "------------------------------------------------------------------------\n",
      "Training Logistic Regression Classifier with lbfgs solver\n",
      "Training Accurracy: 89.44820909970959%\n",
      "Testing Accurracy: 86.93693693693693%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87        57\n",
      "           1       0.83      0.56      0.67        61\n",
      "           2       0.78      0.91      0.84       122\n",
      "           3       0.96      0.92      0.94       204\n",
      "\n",
      "    accuracy                           0.87       444\n",
      "   macro avg       0.85      0.83      0.83       444\n",
      "weighted avg       0.88      0.87      0.87       444\n",
      "\n",
      "Mean F1 score: 0.8283040110496392\n",
      "Accuracy after applying cross validation: 0.82830 (+/- 0.02952)\n",
      "------------------------------------------------------------------------\n",
      "Training Logistic Regression Classifier with sag solver\n",
      "Training Accurracy: 87.99612778315586%\n",
      "Testing Accurracy: 82.65765765765765%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.81        57\n",
      "           1       0.64      0.41      0.50        61\n",
      "           2       0.75      0.84      0.79       122\n",
      "           3       0.94      0.93      0.93       204\n",
      "\n",
      "    accuracy                           0.83       444\n",
      "   macro avg       0.77      0.76      0.76       444\n",
      "weighted avg       0.82      0.83      0.82       444\n",
      "\n",
      "Mean F1 score: 0.7926808805341248\n",
      "Accuracy after applying cross validation: 0.79268 (+/- 0.03122)\n",
      "------------------------------------------------------------------------\n",
      "Training Logistic Regression Classifier with saga solver\n",
      "Training Accurracy: 87.41529525653436%\n",
      "Testing Accurracy: 81.53153153153153%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.88      0.80        57\n",
      "           1       0.61      0.36      0.45        61\n",
      "           2       0.73      0.84      0.78       122\n",
      "           3       0.94      0.92      0.93       204\n",
      "\n",
      "    accuracy                           0.82       444\n",
      "   macro avg       0.75      0.75      0.74       444\n",
      "weighted avg       0.81      0.82      0.81       444\n",
      "\n",
      "Mean F1 score: 0.7719003261044699\n",
      "Accuracy after applying cross validation: 0.77190 (+/- 0.03370)\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# separate the features and target variable\n",
    "X = df.drop('Body_Level', axis=1)\n",
    "y = df['Body_Level']\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size=0.3, random_state=42) \n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "for solver in ('newton-cg', 'lbfgs', 'sag', 'saga'):\n",
    "    print(f\"Training Logistic Regression Classifier with {solver} solver\")\n",
    "    model = LogisticRegression(multi_class = \"multinomial\",solver = solver,max_iter = 30000).fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_train_predict = model.predict(X_train)\n",
    "    print(f\"Training Accurracy: {accuracy_score(y_train, y_train_predict) * 100}%\")\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    print(f\"Testing Accurracy: {accuracy_score(y_test, y_test_predict) * 100}%\")\n",
    "\n",
    "\n",
    "    # create a KFold object\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    # perform cross-validation\n",
    "    scores = cross_val_score(model, X, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "    # Print the classification report and mean F1 score\n",
    "    print(classification_report(y_test, model.predict(X_test)))\n",
    "    print(\"Mean F1 score:\", scores.mean())\n",
    "\n",
    "    # print the mean and standard deviation of the scores\n",
    "    print(f\"Accuracy after applying cross validation: {scores.mean():.5f} (+/- {scores.std():.5f})\")\n",
    "    print(\"------------------------------------------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### penalty Parameter: \n",
    "The regularization penalty to be used. This can be 'l1', 'l2', 'elasticnet', or 'none'. The default value is 'l2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression Classifier with l2 Regularization\n",
      "Training Accurracy: 89.44820909970959%\n",
      "Testing Accurracy: 86.93693693693693%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87        57\n",
      "           1       0.83      0.56      0.67        61\n",
      "           2       0.78      0.91      0.84       122\n",
      "           3       0.96      0.92      0.94       204\n",
      "\n",
      "    accuracy                           0.87       444\n",
      "   macro avg       0.85      0.83      0.83       444\n",
      "weighted avg       0.88      0.87      0.87       444\n",
      "\n",
      "Mean F1 score: 0.8283040110496392\n",
      "Accuracy after applying cross validation: 0.82830 (+/- 0.02952)\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# separate the features and target variable\n",
    "X = df.drop('Body_Level', axis=1)\n",
    "y = df['Body_Level']\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size=0.3, random_state=42) \n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "penalty = 'l2'\n",
    "print(f\"Training Logistic Regression Classifier with {penalty} Regularization\")\n",
    "model = LogisticRegression(multi_class = \"multinomial\",solver = 'lbfgs', penalty = penalty,max_iter = 50000).fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_train_predict = model.predict(X_train)\n",
    "print(f\"Training Accurracy: {accuracy_score(y_train, y_train_predict) * 100}%\")\n",
    "y_test_predict = model.predict(X_test)\n",
    "print(f\"Testing Accurracy: {accuracy_score(y_test, y_test_predict) * 100}%\")\n",
    "\n",
    "\n",
    "# create a KFold object\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# perform cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "# Print the classification report and mean F1 score\n",
    "print(classification_report(y_test, model.predict(X_test)))\n",
    "print(\"Mean F1 score:\", scores.mean())\n",
    "\n",
    "# print the mean and standard deviation of the scores\n",
    "print(f\"Accuracy after applying cross validation: {scores.mean():.5f} (+/- {scores.std():.5f})\")\n",
    "print(\"------------------------------------------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C Parameter: \n",
    "The inverse of the regularization strength. Smaller values of C specify stronger regularization. The default value is 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression Classifier with 0.1 Regularization strength\n",
      "Training Accurracy: 84.12391093901257%\n",
      "Testing Accurracy: 80.85585585585585%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.93      0.83        57\n",
      "           1       0.71      0.44      0.55        61\n",
      "           2       0.70      0.84      0.76       122\n",
      "           3       0.94      0.86      0.90       204\n",
      "\n",
      "    accuracy                           0.81       444\n",
      "   macro avg       0.77      0.77      0.76       444\n",
      "weighted avg       0.82      0.81      0.80       444\n",
      "\n",
      "Mean F1 score: 0.7807256306708318\n",
      "Accuracy after applying cross validation: 0.78073 (+/- 0.04378)\n",
      "------------------------------------------------------------------------\n",
      "Training Logistic Regression Classifier with 0.2 Regularization strength\n",
      "Training Accurracy: 86.64085188770572%\n",
      "Testing Accurracy: 83.55855855855856%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85        57\n",
      "           1       0.74      0.46      0.57        61\n",
      "           2       0.74      0.87      0.80       122\n",
      "           3       0.95      0.90      0.92       204\n",
      "\n",
      "    accuracy                           0.84       444\n",
      "   macro avg       0.80      0.79      0.78       444\n",
      "weighted avg       0.84      0.84      0.83       444\n",
      "\n",
      "Mean F1 score: 0.7997628579952323\n",
      "Accuracy after applying cross validation: 0.79976 (+/- 0.02771)\n",
      "------------------------------------------------------------------------\n",
      "Training Logistic Regression Classifier with 0.3 Regularization strength\n",
      "Training Accurracy: 87.60890609874153%\n",
      "Testing Accurracy: 84.68468468468468%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86        57\n",
      "           1       0.78      0.46      0.58        61\n",
      "           2       0.75      0.88      0.81       122\n",
      "           3       0.95      0.91      0.93       204\n",
      "\n",
      "    accuracy                           0.85       444\n",
      "   macro avg       0.81      0.80      0.79       444\n",
      "weighted avg       0.85      0.85      0.84       444\n",
      "\n",
      "Mean F1 score: 0.8093840156234903\n",
      "Accuracy after applying cross validation: 0.80938 (+/- 0.02895)\n",
      "------------------------------------------------------------------------\n",
      "Training Logistic Regression Classifier with 0.4 Regularization strength\n",
      "Training Accurracy: 87.89932236205227%\n",
      "Testing Accurracy: 85.13513513513513%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.86        57\n",
      "           1       0.78      0.51      0.61        61\n",
      "           2       0.76      0.88      0.81       122\n",
      "           3       0.95      0.91      0.93       204\n",
      "\n",
      "    accuracy                           0.85       444\n",
      "   macro avg       0.82      0.81      0.81       444\n",
      "weighted avg       0.86      0.85      0.85       444\n",
      "\n",
      "Mean F1 score: 0.8135811694591271\n",
      "Accuracy after applying cross validation: 0.81358 (+/- 0.02974)\n",
      "------------------------------------------------------------------------\n",
      "Training Logistic Regression Classifier with 0.5 Regularization strength\n",
      "Training Accurracy: 88.18973862536302%\n",
      "Testing Accurracy: 85.58558558558559%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.86        57\n",
      "           1       0.79      0.51      0.62        61\n",
      "           2       0.76      0.89      0.82       122\n",
      "           3       0.96      0.91      0.93       204\n",
      "\n",
      "    accuracy                           0.86       444\n",
      "   macro avg       0.83      0.82      0.81       444\n",
      "weighted avg       0.86      0.86      0.85       444\n",
      "\n",
      "Mean F1 score: 0.8111707866449249\n",
      "Accuracy after applying cross validation: 0.81117 (+/- 0.03048)\n",
      "------------------------------------------------------------------------\n",
      "Training Logistic Regression Classifier with 0.6 Regularization strength\n",
      "Training Accurracy: 88.48015488867377%\n",
      "Testing Accurracy: 86.03603603603604%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.86        57\n",
      "           1       0.80      0.52      0.63        61\n",
      "           2       0.77      0.90      0.83       122\n",
      "           3       0.96      0.91      0.94       204\n",
      "\n",
      "    accuracy                           0.86       444\n",
      "   macro avg       0.83      0.82      0.82       444\n",
      "weighted avg       0.87      0.86      0.86       444\n",
      "\n",
      "Mean F1 score: 0.8149681233490759\n",
      "Accuracy after applying cross validation: 0.81497 (+/- 0.03372)\n",
      "------------------------------------------------------------------------\n",
      "Training Logistic Regression Classifier with 0.7 Regularization strength\n",
      "Training Accurracy: 88.48015488867377%\n",
      "Testing Accurracy: 86.26126126126125%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.86        57\n",
      "           1       0.80      0.54      0.65        61\n",
      "           2       0.77      0.90      0.83       122\n",
      "           3       0.96      0.91      0.94       204\n",
      "\n",
      "    accuracy                           0.86       444\n",
      "   macro avg       0.83      0.83      0.82       444\n",
      "weighted avg       0.87      0.86      0.86       444\n",
      "\n",
      "Mean F1 score: 0.8165828345074526\n",
      "Accuracy after applying cross validation: 0.81658 (+/- 0.03248)\n",
      "------------------------------------------------------------------------\n",
      "Training Logistic Regression Classifier with 0.8 Regularization strength\n",
      "Training Accurracy: 88.8673765730881%\n",
      "Testing Accurracy: 86.71171171171171%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87        57\n",
      "           1       0.81      0.56      0.66        61\n",
      "           2       0.78      0.90      0.84       122\n",
      "           3       0.96      0.92      0.94       204\n",
      "\n",
      "    accuracy                           0.87       444\n",
      "   macro avg       0.84      0.83      0.83       444\n",
      "weighted avg       0.87      0.87      0.86       444\n",
      "\n",
      "Mean F1 score: 0.8187669503705208\n",
      "Accuracy after applying cross validation: 0.81877 (+/- 0.03295)\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# separate the features and target variable\n",
    "X = df.drop('Body_Level', axis=1)\n",
    "y = df['Body_Level']\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size=0.3, random_state=42) \n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "for c in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8]:\n",
    "    print(f\"Training Logistic Regression Classifier with {c} Regularization strength\")\n",
    "    model = LogisticRegression(multi_class = \"multinomial\",solver = 'lbfgs', penalty = 'l2', C=c ,max_iter = 50000).fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_train_predict = model.predict(X_train)\n",
    "    print(f\"Training Accurracy: {accuracy_score(y_train, y_train_predict) * 100}%\")\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    print(f\"Testing Accurracy: {accuracy_score(y_test, y_test_predict) * 100}%\")\n",
    "\n",
    "\n",
    "    # create a KFold object\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    # perform cross-validation\n",
    "    scores = cross_val_score(model, X, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "    # Print the classification report and mean F1 score\n",
    "    print(classification_report(y_test, model.predict(X_test)))\n",
    "    print(\"Mean F1 score:\", scores.mean())\n",
    "\n",
    "    # print the mean and standard deviation of the scores\n",
    "    print(f\"Accuracy after applying cross validation: {scores.mean():.5f} (+/- {scores.std():.5f})\")\n",
    "    print(\"------------------------------------------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class_weight Parameter: \n",
    "The weights to assign to each class. This can be 'balanced' to automatically adjust the weights based on the class frequencies, or a dictionary with custom weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accurracy: 86.44724104549854%\n",
      "Testing Accurracy: 81.98198198198197%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83        57\n",
      "           1       0.79      0.31      0.45        61\n",
      "           2       0.73      0.82      0.77       122\n",
      "           3       0.91      0.94      0.92       204\n",
      "\n",
      "    accuracy                           0.82       444\n",
      "   macro avg       0.79      0.75      0.74       444\n",
      "weighted avg       0.82      0.82      0.80       444\n",
      "\n",
      "Mean F1 score: 0.7711715016511844\n",
      "Accuracy after applying cross validation: 0.77117 (+/- 0.05104)\n"
     ]
    }
   ],
   "source": [
    "# separate the features and target variable\n",
    "X = df.drop('Body_Level', axis=1)\n",
    "y = df['Body_Level']\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size=0.3, random_state=42) \n",
    "\n",
    "\n",
    "# we will use the class_weight parameter to weight the classes\n",
    "frequencies = df['Body_Level'].value_counts()\n",
    "count = df['Body_Level'].count()\n",
    "freq_level1,freq_level2,freq_level3,freq_level4 = frequencies[0]/count,frequencies[1]/count,frequencies[2]/count,frequencies[3]/count\n",
    "class_weight =  {0: freq_level1, 1: freq_level2, 2: freq_level3, 3: freq_level4}\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(class_weight=class_weight,multi_class = \"multinomial\",solver = 'lbfgs', penalty = 'l2', C=0.8 ,max_iter = 50000).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_train_predict = model.predict(X_train)\n",
    "print(f\"Training Accurracy: {accuracy_score(y_train, y_train_predict) * 100}%\")\n",
    "y_test_predict = model.predict(X_test)\n",
    "print(f\"Testing Accurracy: {accuracy_score(y_test, y_test_predict) * 100}%\")\n",
    "\n",
    "\n",
    "# create a KFold object\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# perform cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "# Print the classification report and mean F1 score\n",
    "print(classification_report(y_test, model.predict(X_test)))\n",
    "print(\"Mean F1 score:\", scores.mean())\n",
    "\n",
    "# print the mean and standard deviation of the scores\n",
    "print(f\"Accuracy after applying cross validation: {scores.mean():.5f} (+/- {scores.std():.5f})\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Principle Component Analysis on the features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accurracy: 87.89932236205227%\n",
      "Testing Accurracy: 85.13513513513513%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.86        57\n",
      "           1       0.80      0.54      0.65        61\n",
      "           2       0.77      0.85      0.81       122\n",
      "           3       0.94      0.92      0.93       204\n",
      "\n",
      "    accuracy                           0.85       444\n",
      "   macro avg       0.83      0.81      0.81       444\n",
      "weighted avg       0.85      0.85      0.85       444\n",
      "\n",
      "Mean F1 score: 0.7996258713539676\n",
      "Accuracy after applying cross validation: 0.79963 (+/- 0.04185)\n"
     ]
    }
   ],
   "source": [
    "# separate the features and target variable\n",
    "X = df.drop('Body_Level', axis=1)\n",
    "y = df['Body_Level']\n",
    "\n",
    "pca = PCA(n_components=13)\n",
    "# Fit the PCA model to the data\n",
    "pca.fit(X)\n",
    "# Transform the data using the fitted PCA model\n",
    "X = pca.transform(X)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size=0.3, random_state=42) \n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(multi_class = \"multinomial\",solver = 'lbfgs', penalty = 'l2', C = 0.8 ,max_iter = 50000).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_train_predict = model.predict(X_train)\n",
    "print(f\"Training Accurracy: {accuracy_score(y_train, y_train_predict) * 100}%\")\n",
    "y_test_predict = model.predict(X_test)\n",
    "print(f\"Testing Accurracy: {accuracy_score(y_test, y_test_predict) * 100}%\")\n",
    "\n",
    "\n",
    "# create a KFold object\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# perform cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "# Print the classification report and mean F1 score\n",
    "print(classification_report(y_test, model.predict(X_test)))\n",
    "print(\"Mean F1 score:\", scores.mean())\n",
    "\n",
    "# print the mean and standard deviation of the scores\n",
    "print(f\"Accuracy after applying cross validation: {scores.mean():.5f} (+/- {scores.std():.5f})\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accurracy: 94.28848015488867%\n",
      "Testing Accurracy: 92.11711711711712%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        57\n",
      "           1       0.97      0.52      0.68        61\n",
      "           2       0.87      0.97      0.92       122\n",
      "           3       0.99      0.99      0.99       204\n",
      "\n",
      "    accuracy                           0.92       444\n",
      "   macro avg       0.91      0.87      0.87       444\n",
      "weighted avg       0.93      0.92      0.91       444\n",
      "\n",
      "Mean F1 score: 0.8187669503705208\n",
      "Accuracy after applying cross validation: 0.81877 (+/- 0.03295)\n"
     ]
    }
   ],
   "source": [
    "# separate the features and target variable\n",
    "X = df.drop('Body_Level', axis=1)\n",
    "y = df['Body_Level']\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size=0.3, random_state=42) \n",
    "\n",
    "\n",
    "# Normalized data\n",
    "stand = preprocessing.StandardScaler()\n",
    "X_train = stand.fit_transform(X_train)\n",
    "X_test = stand.fit_transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(multi_class = \"multinomial\",solver = 'lbfgs', penalty = 'l2', C = 0.8 ,max_iter = 50000).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_train_predict = model.predict(X_train)\n",
    "print(f\"Training Accurracy: {accuracy_score(y_train, y_train_predict) * 100}%\")\n",
    "y_test_predict = model.predict(X_test)\n",
    "print(f\"Testing Accurracy: {accuracy_score(y_test, y_test_predict) * 100}%\")\n",
    "\n",
    "\n",
    "# create a KFold object\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# perform cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "# Print the classification report and mean F1 score\n",
    "print(classification_report(y_test, model.predict(X_test)))\n",
    "print(\"Mean F1 score:\", scores.mean())\n",
    "\n",
    "# print the mean and standard deviation of the scores\n",
    "print(f\"Accuracy after applying cross validation: {scores.mean():.5f} (+/- {scores.std():.5f})\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Over Sampling to handle class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accurracy: 96.69117647058823%\n",
      "Testing Accurracy: 96.69117647058823%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       204\n",
      "           1       0.99      0.93      0.96       204\n",
      "           2       0.93      0.98      0.95       204\n",
      "           3       0.98      0.97      0.98       204\n",
      "\n",
      "    accuracy                           0.97       816\n",
      "   macro avg       0.97      0.97      0.97       816\n",
      "weighted avg       0.97      0.97      0.97       816\n",
      "\n",
      "Mean F1 score: 0.8713992065829025\n",
      "Accuracy after applying cross validation: 0.87140 (+/- 0.02132)\n"
     ]
    }
   ],
   "source": [
    "# separate the features and target variable\n",
    "X = df.drop('Body_Level', axis=1)\n",
    "y = df['Body_Level']\n",
    "\n",
    "\n",
    "# Oversampling to balance the data\n",
    "smote = SMOTE(random_state=42)\n",
    "X, y = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size=0.3, random_state=42) \n",
    "\n",
    "\n",
    "# Normalized data\n",
    "stand = preprocessing.StandardScaler()\n",
    "X_train = stand.fit_transform(X_train)\n",
    "X_test = stand.fit_transform(X_test)\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(multi_class = \"multinomial\",solver = 'lbfgs', penalty = 'l2', C = 0.8 ,max_iter = 50000).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_train_predict = model.predict(X_train)\n",
    "print(f\"Training Accurracy: {accuracy_score(y_train, y_train_predict) * 100}%\")\n",
    "y_test_predict = model.predict(X_test)\n",
    "print(f\"Testing Accurracy: {accuracy_score(y_test, y_test_predict) * 100}%\")\n",
    "\n",
    "\n",
    "# create a KFold object\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# perform cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "# Print the classification report and mean F1 score\n",
    "print(classification_report(y_test, model.predict(X_test)))\n",
    "print(\"Mean F1 score:\", scores.mean())\n",
    "\n",
    "# print the mean and standard deviation of the scores\n",
    "print(f\"Accuracy after applying cross validation: {scores.mean():.5f} (+/- {scores.std():.5f})\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accurracy: 96.84873949579831%\n",
      "Testing Accurracy: 96.20098039215686%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       204\n",
      "           1       0.98      0.90      0.94       204\n",
      "           2       0.93      0.98      0.96       204\n",
      "           3       1.00      0.97      0.99       204\n",
      "\n",
      "    accuracy                           0.96       816\n",
      "   macro avg       0.96      0.96      0.96       816\n",
      "weighted avg       0.96      0.96      0.96       816\n",
      "\n",
      "Mean F1 score: 0.8321557762678594\n",
      "Accuracy after applying cross validation: 0.83216 (+/- 0.02564)\n"
     ]
    }
   ],
   "source": [
    "# separate the features and target variable\n",
    "X = df[['Age', 'Height', 'Weight','Veg_Consump','Water_Consump','Meal_Count','Phys_Act','Time_E_Dev']]\n",
    "y = df['Body_Level']\n",
    "\n",
    "\n",
    "# Oversampling to balance the data\n",
    "smote = SMOTE(random_state=42)\n",
    "X, y = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size=0.3, random_state=42) \n",
    "\n",
    "\n",
    "# Normalized data\n",
    "stand = preprocessing.StandardScaler()\n",
    "X_train = stand.fit_transform(X_train)\n",
    "X_test = stand.fit_transform(X_test)\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(multi_class = \"multinomial\",solver = 'lbfgs', penalty = 'l2', C = 0.8 ,max_iter = 50000).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_train_predict = model.predict(X_train)\n",
    "print(f\"Training Accurracy: {accuracy_score(y_train, y_train_predict) * 100}%\")\n",
    "y_test_predict = model.predict(X_test)\n",
    "print(f\"Testing Accurracy: {accuracy_score(y_test, y_test_predict) * 100}%\")\n",
    "\n",
    "\n",
    "# create a KFold object\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# perform cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "# Print the classification report and mean F1 score\n",
    "print(classification_report(y_test, model.predict(X_test)))\n",
    "print(\"Mean F1 score:\", scores.mean())\n",
    "\n",
    "# print the mean and standard deviation of the scores\n",
    "print(f\"Accuracy after applying cross validation: {scores.mean():.5f} (+/- {scores.std():.5f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df0893f56f349688326838aaeea0de204df53a132722cbd565e54b24a8fec5f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
